# GTFS Backend API

Modern, asenkron ve Ã¶lÃ§eklenebilir **GTFS (General Transit Feed Specification)** veri yÃ¶netim sistemi. Toplu taÅŸÄ±ma verilerini (otobÃ¼s, metro, tren) standart GTFS formatÄ±nda iÅŸler ve RESTful API Ã¼zerinden sunar.

## ğŸš€ Ã–zellikler

### ğŸ“¦ GTFS Veri YÃ¶netimi
- **ZIP Dosya YÃ¼kleme**: GTFS standart dosyalarÄ±nÄ± (11 adet .txt) toplu yÃ¼kleme
- **Asenkron Ä°ÅŸlem**: BÃ¼yÃ¼k dosyalar iÃ§in non-blocking background processing
- **Snapshot Sistemi**: Veri versiyonlama ve aynÄ± anda birden fazla GTFS seti
- **Bulk Insert**: YÃ¼ksek performanslÄ± toplu veri ekleme (thread-pool ile)
- **Referans BÃ¼tÃ¼nlÃ¼ÄŸÃ¼**: GTFS baÄŸÄ±mlÄ±lÄ±klarÄ±na uygun sÄ±ralÄ± iÅŸlem

### ğŸ—„ï¸ Desteklenen GTFS TablolarÄ±
- `agency.txt` - UlaÅŸÄ±m ajanslarÄ±
- `routes.txt` - GÃ¼zergahlar (otobÃ¼s hatlarÄ±)
- `stops.txt` - Duraklar (GPS koordinatlarÄ± ile)
- `trips.txt` - Tekil seferler
- `stop_times.txt` - Durak zamanlarÄ±
- `calendar.txt` / `calendar_dates.txt` - Servis takvimleri
- `shapes.txt` - GÃ¼zergah geometrileri
- `fare_attributes.txt` / `fare_rules.txt` - Ãœcret bilgileri
- `feed_info.txt` - Feed meta verileri

### ğŸ› ï¸ Teknik Ã–zellikler
- **Thread-Safe**: AyrÄ± DB session'lar ile paralel iÅŸlem
- **Real-time Status**: Upload ilerleme takibi
- **Error Handling**: Robust hata yÃ¶netimi ve rollback
- **Auto Cleanup**: Eski snapshot'larÄ± otomatik temizleme
- **OpenAPI Docs**: Otomatik API dokÃ¼mantasyonu

## ğŸ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### Ã–nkoÅŸullar
- Python 3.10+
- PostgreSQL 12+
- 4GB+ RAM (bÃ¼yÃ¼k GTFS dosyalarÄ± iÃ§in)

### Kurulum
```bash
# 1. Proje klonlama
git clone <repo-url>
cd gtfs-back

# 2. Virtual environment
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# 3. BaÄŸÄ±mlÄ±lÄ±klar
pip install -U pip
pip install -r requirements.txt

# 4. VeritabanÄ± kurulumu
createdb gtfs_db
alembic upgrade head

# 5. Sunucuyu baÅŸlat
uvicorn app.main:app --reload --workers 4
```

### ğŸŒ EriÅŸim NoktalarÄ±
- **API DokÃ¼mantasyonu**: `http://127.0.0.1:8000/docs`
- **SaÄŸlÄ±k KontrolÃ¼**: `http://127.0.0.1:8000/api/health`
- **GTFS Upload**: `http://127.0.0.1:8000/api/gtfs/upload`

## âš™ï¸ YapÄ±landÄ±rma

### Ortam DeÄŸiÅŸkenleri (.env)
```bash
# Uygulama AyarlarÄ±
PROJECT_NAME="GTFS Backend"
DEBUG=false
API_V1_PREFIX="/api"
BACKEND_CORS_ORIGINS=["http://localhost:3000","http://localhost:8080"]

# VeritabanÄ±
DATABASE_URL="postgresql://postgres:password@localhost/gtfs_db"



### VeritabanÄ± Connection Pool
```python
# YÃ¼ksek performans iÃ§in database.py'de:
engine = create_engine(
    DATABASE_URL,
    pool_size=10,        # AynÄ± anda 10 connection
    max_overflow=20,     # Peak'te +20 connection  
    pool_timeout=30,     # 30 saniye timeout
    pool_recycle=3600    # 1 saatte connection yenile
)
```

## ğŸ“š API KullanÄ±mÄ±

### GTFS Dosya YÃ¼kleme
```bash
# ZIP dosyasÄ± yÃ¼kle
curl -X POST "http://localhost:8000/api/gtfs/upload" \
     -F "file=@your_gtfs_data.zip"

# YanÄ±t:
{
  "message": "GTFS upload started successfully",
  "snapshot_id": "abc-123-def",
  "status_url": "/api/gtfs/upload/abc-123-def/status"
}
```

### Upload Durumu Takibi
```bash
# Ä°lerleme kontrolÃ¼
curl "http://localhost:8000/api/gtfs/upload/abc-123-def/status"

# YanÄ±t:
{
  "snapshot_id": "abc-123-def",
  "status": "processing",
  "total_files": 11,
  "processed_files": 7,
  "errors": []
}
```

### Veri Sorgulama
```bash
# Snapshot'larÄ± listele
curl "http://localhost:8000/api/gtfs/snapshots"

# DuraklarÄ± getir
curl "http://localhost:8000/api/stops?snapshot_id=abc-123-def&limit=100"

# GÃ¼zergahlarÄ± getir
curl "http://localhost:8000/api/routes?snapshot_id=abc-123-def"
```

## ğŸ§ª Test

```bash
# TÃ¼m testleri Ã§alÄ±ÅŸtÄ±r
pytest -v

# Sadece upload testleri
pytest tests/test_gtfs_upload.py -v

# Coverage raporu
pytest --cov=app --cov-report=html
```

## ğŸ“ Proje YapÄ±sÄ±

```
gtfs-back/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes/           # API endpoint'leri
â”‚   â”‚   â”‚   â”œâ”€â”€ gtfs.py       # GTFS upload/management
â”‚   â”‚   â”‚   â”œâ”€â”€ agency.py     # Agency CRUD
â”‚   â”‚   â”‚   â”œâ”€â”€ routes.py     # Routes CRUD
â”‚   â”‚   â”‚   â”œâ”€â”€ stops.py      # Stops CRUD
â”‚   â”‚   â”‚   â””â”€â”€ ...           # DiÄŸer GTFS tablolarÄ±
â”‚   â”‚   â””â”€â”€ router.py         # Ana router
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py         # Ayarlar
â”‚   â”‚   â””â”€â”€ logging_config.py # Log yapÄ±landÄ±rmasÄ±
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ database.py       # DB baÄŸlantÄ±sÄ±
â”‚   â”‚   â””â”€â”€ migrations/       # Alembic migrations
â”‚   â”œâ”€â”€ models/               # SQLAlchemy modelleri
â”‚   â”‚   â”œâ”€â”€ agency.py
â”‚   â”‚   â”œâ”€â”€ routes.py
â”‚   â”‚   â””â”€â”€ ...              # GTFS tablolarÄ±
â”‚   â”œâ”€â”€ schemas/              # Pydantic ÅŸemalarÄ±
â”‚   â”œâ”€â”€ services/             # Ä°ÅŸ mantÄ±ÄŸÄ±
â”‚   â”‚   â”œâ”€â”€ gtfs_upload.py    # GTFS iÅŸleme servisi
â”‚   â”‚   â””â”€â”€ ...              # CRUD servisleri
â”‚   â””â”€â”€ main.py              # FastAPI uygulamasÄ±
â”œâ”€â”€ tests/                   # Test dosyalarÄ±
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ alembic.ini
â””â”€â”€ README.md
```

## ğŸš€ Performans Ã–zellikleri

### Asenkron Ä°ÅŸlem Mimarisi
- **Non-blocking Upload**: BÃ¼yÃ¼k dosyalar arka planda iÅŸlenir
- **Thread Pool**: SQLAlchemy operations background thread'de
- **Event Loop Yield**: CPU kontrolÃ¼ dÃ¼zenli olarak bÄ±rakÄ±lÄ±r
- **Parallel Requests**: Upload sÄ±rasÄ±nda diÄŸer API'ler Ã§alÄ±ÅŸÄ±r

### Optimizasyon Teknikleri
```python
# Bulk insert - 1000x daha hÄ±zlÄ±
await loop.run_in_executor(None, lambda: db.execute(table.insert(), batch))

# Batch processing - Memory efficient
batch_size = 500  # 500'lÃ¼k gruplar halinde iÅŸlem

# Connection pooling - Concurrent access
pool_size=10, max_overflow=20
```

### Benchmark SonuÃ§larÄ±
| Dosya Boyutu | KayÄ±t SayÄ±sÄ± | Ä°ÅŸlem SÃ¼resi | Memory |
|--------------|-------------|-------------|---------|
| 50MB        | 500K        | ~2 dakika   | ~1GB   |
| 200MB       | 2M          | ~8 dakika   | ~2GB   |
| 1GB         | 10M         | ~30 dakika  | ~4GB   |

## ğŸ› ï¸ GeliÅŸtirme

### Database Migration
```bash
# Yeni migration oluÅŸtur
alembic revision --autogenerate -m "Add new table"

# Migration uygula
alembic upgrade head

# Migration geri al
alembic downgrade -1
```

### Debug Modu
```bash
# Debug logging ile Ã§alÄ±ÅŸtÄ±r
DEBUG=true uvicorn app.main:app --reload --log-level debug

# SQL query'lerini gÃ¶rmek iÃ§in
echo "engine = create_engine(DATABASE_URL, echo=True)" >> app/db/database.py
```

## ğŸ¤ KatkÄ±da Bulunma

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. Commit yapÄ±n (`git commit -m 'Add amazing feature'`)
4. Push edin (`git push origin feature/amazing-feature`)
5. Pull Request aÃ§Ä±n

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r.

## ğŸ™ TeÅŸekkÃ¼rler

- **FastAPI** - Modern, hÄ±zlÄ± web framework
- **SQLAlchemy** - GÃ¼Ã§lÃ¼ ORM
- **PostgreSQL** - GÃ¼venilir veritabanÄ±
- **GTFS Community** - AÃ§Ä±k veri standardÄ±

---

**âš¡ HÄ±zlÄ±, Ã¶lÃ§eklenebilir ve gÃ¼venilir GTFS veri yÃ¶netimi iÃ§in tasarlandÄ±!**
